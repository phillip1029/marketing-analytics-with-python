{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4 Regression Analysis for Marketing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Introduction to Regression Analysis\n",
    "\n",
    "Regression analysis stands as a cornerstone of marketing analytics, offering a powerful toolkit for deciphering the intricate dynamics between various factors influencing market outcomes. This statistical approach enables marketers to navigate through the complexity of consumer behavior, advertising effectiveness, pricing strategies, and more, by establishing quantifiable relationships between dependent variables and one or more independent variables.\n",
    "\n",
    "### Applications in Marketing\n",
    "\n",
    "The versatility of regression analysis makes it indispensable in the realm of marketing. Here are some ways it can be applied:\n",
    "\n",
    "- **Forecasting Sales:** By incorporating variables such as marketing expenditure, seasonal trends, and economic indicators, businesses can predict future sales, enabling better inventory and budget planning.\n",
    "- **Advertising Effectiveness:** Evaluating the ROI on advertising campaigns by analyzing how different channels and messaging impact customer acquisition and retention.\n",
    "- **Customer Insights:** Understanding what drives customer satisfaction and loyalty by examining factors such as service quality, product features, and user experience.\n",
    "- **Pricing Optimization:** Assessing how price changes influence demand and sales, aiding in the development of dynamic pricing strategies to maximize profitability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Types of Regression Analysis\n",
    "\n",
    "Regression analysis is a versatile statistical tool used to examine the relationship between a dependent (target) variable and one or more independent (predictor) variables. The choice of regression analysis depends on the nature of the target variable and the relationship you wish to investigate. Below, we discuss several commonly used types of regression analysis, each serving distinct analytical needs in marketing analytics.\n",
    "\n",
    "### 4.2.1 Linear Regression\n",
    "\n",
    "**Linear regression** is the most straightforward form of regression analysis. It assumes a linear relationship between the dependent variable and one or more independent variables. This model is highly interpretable and is often used as a starting point for understanding relationships between variables.\n",
    "\n",
    "- **Usage:** Ideal for continuous data and forecasting outcomes like sales volume based on advertising spend.\n",
    "- **Python Implementation:** Widely supported by libraries such as Scikit-learn (`LinearRegression`) and Statsmodels.\n",
    "\n",
    "### 4.2.2 Logistic Regression\n",
    "\n",
    "Unlike linear regression, **logistic regression** is used when the dependent variable is categorical, typically binary. This model estimates probabilities by predicting the log odds of the outcome, making it suitable for classification tasks.\n",
    "\n",
    "- **Usage:** Commonly applied to predict binary outcomes such as customer churn (yes/no) or conversion success (purchase/no purchase).\n",
    "- **Python Implementation:** Can be implemented using Scikit-learn's `LogisticRegression` class.\n",
    "\n",
    "### 4.2.3 Poisson Regression\n",
    "\n",
    "**Poisson regression** is a specialized form of regression analysis used when the dependent variable is count data. This type of regression is particularly useful for modeling the number of times an event occurs within a fixed interval of time or space. Given its nature, Poisson regression is a powerful tool for analyzing and predicting behaviors or trends where outcomes are discrete counts.\n",
    "\n",
    "- **Usage:** Poisson regression is ideal for count-based data scenarios such as predicting the number of website visits, daily sales transactions, or call center calls received in a day. It helps in understanding how various factors or exposures influence the rate at which events occur.\n",
    "\n",
    "- **Assumptions:** The model assumes that the mean and variance of the distribution of the dependent variable are equal, a condition known as equidispersion. However, real-world data often violate this assumption, leading to overdispersion or underdispersion. In such cases, alternative models like Negative Binomial regression may be more appropriate.\n",
    "\n",
    "- **Python Implementation:** The `statsmodels` library in Python provides functionality to fit Poisson regression models.\n",
    "\n",
    "### 4.2.4 Polynomial Regression\n",
    "\n",
    "**Polynomial regression** extends linear regression by introducing polynomial terms (squared, cubic, etc.) of the independent variables. This allows the model to capture nonlinear relationships between the dependent and independent variables.\n",
    "\n",
    "- **Usage:** Useful when the relationship between variables is not linear but still requires the simplicity and interpretability of regression models.\n",
    "- **Python Implementation:** Achieved by transforming features into polynomial features (e.g., using Scikit-learn's `PolynomialFeatures`) before applying linear regression.\n",
    "\n",
    "### 4.2.5 Stepwise Regression\n",
    "\n",
    "**Stepwise regression** is a systematic method for adding and removing predictors based on their statistical significance in explaining the variance of the dependent variable. It aims to identify the most parsimonious model that explains the data.\n",
    "\n",
    "- **Usage:** Effective in scenarios with large numbers of predictors, identifying a subset that offers the best prediction.\n",
    "- **Python Implementation:** Can be complex to implement directly but is supported through procedures in statistical packages like Statsmodels.\n",
    "\n",
    "### 4.2.6 Ridge and Lasso Regression\n",
    "\n",
    "Both **Ridge** and **Lasso regression** are techniques used to analyze data with multicollinearity or when the number of predictors exceeds the number of observations. They introduce a penalty term to the loss function to shrink coefficient estimates.\n",
    "\n",
    "- **Ridge Regression** (L2 regularization) minimizes the sum of the square of coefficients, effectively reducing model complexity.\n",
    "  \n",
    "- **Lasso Regression** (L1 regularization) can shrink some coefficients to zero, performing variable selection.\n",
    "\n",
    "- **Usage:** Both are used for feature selection, regularization, and improving model predictions in high-dimensional datasets.\n",
    "- **Python Implementation:** Scikit-learn offers `Ridge` and `Lasso` classes under its linear models module.\n",
    " \n",
    "### 4.2.7 Generalized Linear Regression (GLM)\n",
    "\n",
    "**Generalized Linear Regression (GLM)** extend traditional linear regression models to accommodate response variables that are not normally distributed. GLMs are versatile, allowing for the specification of different distributions for the response variable and the use of a link function to model the relationship between the response variable and the predictors. This flexibility makes GLMs a powerful tool for a wide range of data types and analytical tasks.\n",
    "\n",
    "- **Usage:** GLMs are broadly applicable in marketing analytics, from modeling binary outcomes like conversion or churn with logistic regression, to modeling count data, such as the number of purchases made by a customer, using Poisson or Negative Binomial regression.\n",
    "\n",
    "- **Components:** A GLM is characterized by three components: the probability distribution of the response variable (from the exponential family), the linear predictor (a linear combination of the input variables), and the link function (which connects the expected value of the response to the linear predictor).\n",
    "\n",
    "- **Python Implementation:** Implementing GLMs in Python can be readily done with the `statsmodels` library, which supports a variety of families for the response distribution (e.g., Binomial for binary data, Poisson for count data). \n",
    "### Choosing the Right Model\n",
    "\n",
    "Selecting the appropriate regression model depends on several factors, including the nature of the dependent variable, the relationship between the independent and dependent variables, and the specific analytical objectives. Experimentation and validation are key to determining the most effective model for your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4.3 Linear Regression\n",
    "\n",
    "At the heart of regression analysis is linear regression, a model that assumes a linear relationship between the dependent and independent variables. This simplicity makes it not only a starting point for analysis but also a tool for making predictions and decisions in marketing strategies.\n",
    "\n",
    "### 4.3.1 The Linear Regression Model\n",
    "\n",
    "The linear regression model can be expressed in the formula:\n",
    "\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\ldots + \\beta_ix_i + \\epsilon\n",
    "$$\n",
    "\n",
    "Here, $y$ represents the dependent variable we aim to predict, such as sales volume or customer satisfaction scores. The $x$ variables are the independent variables or predictors, such as advertising spend, product price, or customer demographics. $\\beta$ coefficients quantify the impact of each predictor on the dependent variable, and $\\epsilon$ is the error term, accounting for the variability not explained by the model.\n",
    "\n",
    "### 4.3.2 Interpreting Coefficients\n",
    "\n",
    "Understanding the coefficients in a linear regression model is crucial for making informed marketing decisions. A positive coefficient for a variable, such as marketing spend, indicates a direct relationship with the dependent variable, suggesting that increasing the marketing budget could lead to higher sales. Conversely, a negative coefficient suggests an inverse relationship, providing insights into factors that might hinder performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4.3.3 Implementing Linear Regression with Scikit-learn\n",
    "\n",
    "Scikit-learn, a comprehensive Python library for machine learning, simplifies the process of implementing linear regression models. It offers an intuitive interface and efficient tools for model fitting, prediction, and evaluation, making it an excellent choice for marketing analytics projects.\n",
    "\n",
    "Below are the general steps to build a regression model:\n",
    "\n",
    "1. **Data Preparation:** Begin by loading your dataset and selecting the dependent and independent variables. It's important to clean and preprocess your data, handling missing values, and encoding categorical variables as needed.\n",
    "\n",
    "2. **Model Setup:** Import the `LinearRegression` class from Scikit-learn's `linear_model` module. Instantiate the model with appropriate parameters.\n",
    "\n",
    "3. **Model Fitting:** Use the `fit` method to train your model on the data. This involves finding the coefficients that minimize the error term.\n",
    "\n",
    "4. **Prediction and Evaluation:** With the model trained, use it to make predictions on new or test data. Evaluate the model's performance using metrics such as R-squared and mean squared error to understand its accuracy and reliability.\n",
    "\n",
    "5. **Interpretation:** Analyze the model's coefficients to draw insights into the relationships between your variables. This step is critical for applying your findings to make informed marketing decisions.\n",
    "\n",
    "By following these steps, you can leverage linear regression in Scikit-learn to uncover valuable marketing insights, predict outcomes, and optimize strategies for better performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Social Media</th>\n",
       "      <th>Influencer</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Low</td>\n",
       "      <td>3.518070</td>\n",
       "      <td>2.293790</td>\n",
       "      <td>Micro</td>\n",
       "      <td>55.261284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Low</td>\n",
       "      <td>7.756876</td>\n",
       "      <td>2.572287</td>\n",
       "      <td>Mega</td>\n",
       "      <td>67.574904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>High</td>\n",
       "      <td>20.348988</td>\n",
       "      <td>1.227180</td>\n",
       "      <td>Micro</td>\n",
       "      <td>272.250108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Medium</td>\n",
       "      <td>20.108487</td>\n",
       "      <td>2.728374</td>\n",
       "      <td>Mega</td>\n",
       "      <td>195.102176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>High</td>\n",
       "      <td>31.653200</td>\n",
       "      <td>7.776978</td>\n",
       "      <td>Nano</td>\n",
       "      <td>273.960377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TV      Radio  Social Media Influencer       Sales\n",
       "0     Low   3.518070      2.293790      Micro   55.261284\n",
       "1     Low   7.756876      2.572287       Mega   67.574904\n",
       "2    High  20.348988      1.227180      Micro  272.250108\n",
       "3  Medium  20.108487      2.728374       Mega  195.102176\n",
       "4    High  31.653200      7.776978       Nano  273.960377"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "# Import the data\n",
    "data = pd.read_csv('data\\marketing_sales_data.csv')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Social Media</th>\n",
       "      <th>Influencer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.984101</td>\n",
       "      <td>3.518070</td>\n",
       "      <td>2.293790</td>\n",
       "      <td>188.321846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.984101</td>\n",
       "      <td>7.756876</td>\n",
       "      <td>2.572287</td>\n",
       "      <td>194.487941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300.853195</td>\n",
       "      <td>20.348988</td>\n",
       "      <td>1.227180</td>\n",
       "      <td>188.321846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195.358032</td>\n",
       "      <td>20.108487</td>\n",
       "      <td>2.728374</td>\n",
       "      <td>194.487941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300.853195</td>\n",
       "      <td>31.653200</td>\n",
       "      <td>7.776978</td>\n",
       "      <td>191.874432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TV      Radio  Social Media  Influencer\n",
       "0   90.984101   3.518070      2.293790  188.321846\n",
       "1   90.984101   7.756876      2.572287  194.487941\n",
       "2  300.853195  20.348988      1.227180  188.321846\n",
       "3  195.358032  20.108487      2.728374  194.487941\n",
       "4  300.853195  31.653200      7.776978  191.874432"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# processed marketing dataset\n",
    "X = data[['TV', 'Radio', 'Social Media', 'Influencer']]  # Independent variables\n",
    "y = data['Sales']  # Dependent variable\n",
    "\n",
    "# separate the features into categorical and numerical features\n",
    "categorical_features = [ 'TV', 'Influencer']\n",
    "numerical_features = ['Social Media','Radio']\n",
    "\n",
    "# target encoding for categorical features\n",
    "def target_encoding(data, column, target):\n",
    "    \n",
    "    grouped = data[[column,target]].groupby(column,as_index=False).mean()\n",
    "    empty_dict = {}\n",
    "    for i in range(len(grouped)):\n",
    "        empty_dict[grouped.iloc[i,0]]=grouped.iloc[i,1]\n",
    "    data[column]=data[column].map(lambda x: empty_dict[x])\n",
    "    \n",
    "    return data\n",
    "\n",
    "# combine X and y to apply target encoding\n",
    "X['Sales'] = y\n",
    "\n",
    "X_te=data.copy()\n",
    "for col in categorical_features:\n",
    "    target_encoding(X_te, col, 'Sales')\n",
    "\n",
    "# separate the features into X and y\n",
    "y = X_te['Sales']\n",
    "X = X_te.drop('Sales', axis=1)\n",
    "\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we define a function for target encoding of categorical features. This function replaces each unique value in the specified column with the mean of the target column for that value.\n",
    "\n",
    "From the data examples above, we can see that features are at different scales. We usually standardize the features before we can estimate the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Social Media</th>\n",
       "      <th>Influencer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.173289</td>\n",
       "      <td>-1.508439</td>\n",
       "      <td>-0.465035</td>\n",
       "      <td>-0.210564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.173289</td>\n",
       "      <td>-1.051809</td>\n",
       "      <td>-0.340507</td>\n",
       "      <td>1.120998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.331340</td>\n",
       "      <td>0.304689</td>\n",
       "      <td>-0.941962</td>\n",
       "      <td>-0.210564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.072335</td>\n",
       "      <td>0.278781</td>\n",
       "      <td>-0.270713</td>\n",
       "      <td>1.120998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.331340</td>\n",
       "      <td>1.522447</td>\n",
       "      <td>1.986735</td>\n",
       "      <td>0.556614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         TV     Radio  Social Media  Influencer\n",
       "0 -1.173289 -1.508439     -0.465035   -0.210564\n",
       "1 -1.173289 -1.051809     -0.340507    1.120998\n",
       "2  1.331340  0.304689     -0.941962   -0.210564\n",
       "3  0.072335  0.278781     -0.270713    1.120998\n",
       "4  1.331340  1.522447      1.986735    0.556614"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standardize the numerical features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "all_features = X.columns\n",
    "# all the features in X are numerical\n",
    "X = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X, columns=all_features)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Sales   R-squared:                       0.905\n",
      "Model:                            OLS   Adj. R-squared:                  0.904\n",
      "Method:                 Least Squares   F-statistic:                     1074.\n",
      "Date:                Thu, 04 Apr 2024   Prob (F-statistic):          3.23e-229\n",
      "Time:                        02:02:08   Log-Likelihood:                -2168.0\n",
      "No. Observations:                 457   AIC:                             4346.\n",
      "Df Residuals:                     452   BIC:                             4367.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const          190.1769      1.309    145.249      0.000     187.604     192.750\n",
      "TV              59.9624      2.250     26.649      0.000      55.540      64.384\n",
      "Radio           27.2419      2.391     11.393      0.000      22.543      31.941\n",
      "Social Media     0.6669      1.678      0.398      0.691      -2.630       3.964\n",
      "Influencer       0.1651      1.329      0.124      0.901      -2.447       2.778\n",
      "==============================================================================\n",
      "Omnibus:                       50.570   Durbin-Watson:                   1.852\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               15.172\n",
      "Skew:                           0.086   Prob(JB):                     0.000507\n",
      "Kurtosis:                       2.124   Cond. No.                         3.68\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a linear regression model using Scikit-learn\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Create a new dataset with the same features as the training data\n",
    "X_train_sm = sm.add_constant(X_train)\n",
    "\n",
    "# Create an OLS (Ordinary Least Squares) model using Statsmodels\n",
    "model_sm = sm.OLS(y_train, X_train_sm)\n",
    "\n",
    "# Fit the OLS model\n",
    "results_sm = model_sm.fit()\n",
    "\n",
    "# Print the detailed model summary from Statsmodels\n",
    "print(results_sm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results above show the output of an Ordinary Least Squares (OLS) regression model. The model attempts to explain the relationship between the dependent variable \"Sales\" and four independent variables: \"TV,\" \"Radio,\" \"Social Media,\" and \"Influencer.\" Let's go through the main parts of the results:\n",
    "\n",
    "1. R-squared and Adjusted R-squared:\n",
    "   - R-squared (0.905) indicates that approximately 90.5% of the variance in \"Sales\" can be explained by the independent variables included in the model.\n",
    "   - Adjusted R-squared (0.904) is a modified version of R-squared that takes into account the number of predictors in the model. It is slightly lower than R-squared, suggesting that the model's explanatory power is still high even after accounting for the number of variables.\n",
    "\n",
    "2. F-statistic and Prob (F-statistic):\n",
    "   - The F-statistic (1074.0) tests the overall significance of the regression model. A high F-statistic suggests that the model is statistically significant.\n",
    "   - Prob (F-statistic) (3.23e-229) is the p-value associated with the F-statistic. It is extremely low (close to zero), indicating that the model is highly statistically significant.\n",
    "\n",
    "3. Coefficients and their significance:\n",
    "   - The \"coef\" column shows the estimated coefficients for each independent variable.\n",
    "   - \"const\" (190.1769) represents the intercept or the expected value of \"Sales\" when all independent variables are zero.\n",
    "   - \"TV\" (59.9624), \"Radio\" (27.2419), \"Social Media\" (0.6669), and \"Influencer\" (0.1651) are the coefficients for the respective independent variables.\n",
    "   - The \"std err\" column shows the standard errors associated with each coefficient estimate.\n",
    "   - The \"t\" column represents the t-statistic, which measures the statistical significance of each coefficient. Higher absolute values of t-statistic indicate greater significance.\n",
    "   - The \"P>|t|\" column shows the p-value associated with each t-statistic. Lower p-values (typically < 0.05) suggest that the coefficient is statistically significant.\n",
    "   - The \"[0.025, 0.975]\" columns represent the 95% confidence interval for each coefficient estimate.\n",
    "\n",
    "4. Model diagnostics:\n",
    "   - Omnibus, Prob(Omnibus), Skew, and Kurtosis provide information about the normality of the residuals. In this case, the low p-value for the Omnibus test (0.000) suggests that the residuals may not be normally distributed.\n",
    "   - Durbin-Watson (1.852) is a test statistic for autocorrelation in the residuals. A value close to 2 indicates no autocorrelation.\n",
    "   - Jarque-Bera (JB) and Prob(JB) are additional tests for normality of the residuals. The low p-value (0.000507) suggests that the residuals may not be normally distributed.\n",
    "   - Cond. No. (3.68) is the condition number, which measures the sensitivity of the regression estimates to small changes in the input data. A higher value may indicate multicollinearity among the independent variables.\n",
    "\n",
    "**Business Insights Interpretation:**\n",
    "Based on the results, the coefficients for \"TV\" and \"Radio\" are statistically significant (p-values < 0.05), indicating that they have a significant impact on \"Sales.\" The coefficients for \"Social Media\" and \"Influencer\" are not statistically significant (p-values > 0.05), suggesting that they may not have a significant effect on \"Sales.\"\n",
    "\n",
    "However, the diagnostics raise some concerns about the normality of the residuals, which may affect the validity of the model assumptions. Further investigation and potential model refinements may be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Generalized Linear Regression (GLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a Generalized Linear Model (GLM) instead of an Ordinary Least Squares (OLS) model, you can use the `statsmodels.genmod.generalized_linear_model` module in Python. Here's an example of how to create a GLM model using the same data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLM Model Summary:\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                  Sales   No. Observations:                  457\n",
      "Model:                            GLM   Df Residuals:                      452\n",
      "Model Family:                Gaussian   Df Model:                            4\n",
      "Link Function:               identity   Scale:                          781.34\n",
      "Method:                          IRLS   Log-Likelihood:                -2168.0\n",
      "Date:                Thu, 04 Apr 2024   Deviance:                   3.5317e+05\n",
      "Time:                        02:18:05   Pearson chi2:                 3.53e+05\n",
      "No. Iterations:                     3   Pseudo R-squ. (CS):             0.9999\n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const          190.1769      1.309    145.249      0.000     187.611     192.743\n",
      "TV              59.9624      2.250     26.649      0.000      55.552      64.372\n",
      "Radio           27.2419      2.391     11.393      0.000      22.555      31.928\n",
      "Social Media     0.6669      1.678      0.398      0.691      -2.621       3.955\n",
      "Influencer       0.1651      1.329      0.124      0.901      -2.440       2.771\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.genmod.generalized_linear_model import GLM\n",
    "from statsmodels.genmod.families import Gaussian\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Add a constant term to the training and test sets\n",
    "X_train = sm.add_constant(X_train)\n",
    "X_test = sm.add_constant(X_test)\n",
    "\n",
    "# Create the GLM model with Gaussian family and identity link function\n",
    "model = GLM(y_train, X_train, family=Gaussian(link=sm.genmod.families.links.identity()))\n",
    "\n",
    "# Fit the GLM model on the training data\n",
    "results = model.fit()\n",
    "\n",
    "# Print the model summary\n",
    "print(\"GLM Model Summary:\")\n",
    "print(results.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation:\n",
      "Mean Squared Error (MSE): 802.7904830299971\n",
      "R-squared: 0.8974988747706325\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = results.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error (MSE) and R-squared on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Test Set Evaluation:\")\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"R-squared:\", r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example:\n",
    "\n",
    "1. We import the necessary modules from `statsmodels`, including `GLM` from `statsmodels.genmod.generalized_linear_model` and `Gaussian` from `statsmodels.genmod.families`.\n",
    "\n",
    "2. We assume that you have a dataset called `data` with 'Sales' as the dependent variable and 'TV', 'Radio', 'Social Media', and 'Influencer' as independent variables.\n",
    "\n",
    "3. We create the design matrix `X` by adding a constant term to the independent variables using `sm.add_constant()`. This is necessary for including the intercept in the model.\n",
    "\n",
    "4. We create the GLM model using `GLM()` and specify the dependent variable (`data['Sales']`), the design matrix (`X`), and the family and link function. In this case, we use the Gaussian family with the identity link function, which is equivalent to a linear regression model.\n",
    "\n",
    "5. We fit the GLM model using the `fit()` method and store the results in the `results` variable.\n",
    "\n",
    "6. Finally, we print the model summary using `results.summary()`, which will display the coefficients, standard errors, t-values, p-values, and other model diagnostics.\n",
    "\n",
    "The output will be similar to the previous OLS model summary, but with some additional information specific to the GLM framework.\n",
    "\n",
    "Note that in this example, we used the Gaussian family with the identity link function, which makes the GLM model equivalent to a linear regression model. However, GLMs allow for more flexibility in modeling different types of dependent variables and relationships by specifying different families and link functions. For example, you can use the Poisson family for count data or the Binomial family for binary outcomes.\n",
    "\n",
    "Feel free to modify the code and experiment with different families and link functions based on the nature of your data and the specific problem you're trying to solve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results above show the output of a Generalized Linear Model (GLM) regression. The model aims to explain the relationship between the dependent variable \"Sales\" and four independent variables: \"TV,\" \"Radio,\" \"Social Media,\" and \"Influencer.\" Let's go through the main parts of the results:\n",
    "\n",
    "1. Model Family and Link Function:\n",
    "   - The GLM model assumes a Gaussian (normal) distribution for the dependent variable \"Sales.\"\n",
    "   - The link function used is the identity function, which means that the linear predictor is directly related to the expected value of the response variable.\n",
    "\n",
    "2. Goodness of Fit Measures:\n",
    "   - Deviance (3.5317e+05) measures the difference between the fitted model and the saturated model. Lower values indicate a better fit.\n",
    "   - Pearson chi2 (3.53e+05) is another measure of goodness of fit, comparing the observed and expected values. Lower values indicate a better fit.\n",
    "   - Pseudo R-squared (CS) (0.9999) is a measure of the proportion of variance explained by the model. A value close to 1 suggests a good fit.\n",
    "\n",
    "3. Coefficients and their significance:\n",
    "   - The \"coef\" column shows the estimated coefficients for each independent variable.\n",
    "   - \"const\" (190.1769) represents the intercept or the expected value of \"Sales\" when all independent variables are zero.\n",
    "   - \"TV\" (59.9624), \"Radio\" (27.2419), \"Social Media\" (0.6669), and \"Influencer\" (0.1651) are the coefficients for the respective independent variables.\n",
    "   - The \"std err\" column shows the standard errors associated with each coefficient estimate.\n",
    "   - The \"z\" column represents the z-statistic, which measures the statistical significance of each coefficient. Higher absolute values of z-statistic indicate greater significance.\n",
    "   - The \"P>|z|\" column shows the p-value associated with each z-statistic. Lower p-values (typically < 0.05) suggest that the coefficient is statistically significant.\n",
    "   - The \"[0.025, 0.975]\" columns represent the 95% confidence interval for each coefficient estimate.\n",
    "\n",
    "4. Model Summary:\n",
    "   - No. Observations (457) indicates the total number of data points used in the model.\n",
    "   - Df Residuals (452) represents the degrees of freedom for the residuals.\n",
    "   - Df Model (4) represents the degrees of freedom for the model (number of independent variables).\n",
    "   - Scale (781.34) is an estimate of the scale parameter (dispersion) of the model.\n",
    "   - Log-Likelihood (-2168.0) measures the goodness of fit of the model. Higher values indicate a better fit.\n",
    "   - No. Iterations (3) indicates the number of iterations required for the model to converge.\n",
    "\n",
    "**Business Insights Interpretation:**\n",
    "\n",
    "Based on the results, the coefficients for \"TV\" and \"Radio\" are statistically significant (p-values < 0.05), indicating that they have a significant impact on \"Sales.\" The coefficients for \"Social Media\" and \"Influencer\" are not statistically significant (p-values > 0.05), suggesting that they may not have a significant effect on \"Sales.\"\n",
    "\n",
    "The model assumes a Gaussian distribution for the dependent variable, and the identity link function suggests a linear relationship between the predictors and the response variable. The goodness of fit measures (Deviance, Pearson chi2, and Pseudo R-squared) indicate a relatively good fit of the model to the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
